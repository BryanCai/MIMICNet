{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "Trains the neural network on the medical1 dataset. Look into ```home/mldata/KDD/medical1``` for the dataset.\n",
    "This code has been used in most places (py scripts) to train the neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\PeterChe1990\\\\Desktop\\\\Kdd2015DeepPhenotyping'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import tengwar.nnet.NewSdA # multitask logistic regression\n",
    "import tengwar.nnet # all neural network training functions \n",
    "import tengwar.eval # most of the functions to compute performance metrics\n",
    "\n",
    "# all non-neural network baselines\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from tengwar.data import make_theano_shared # make theano shared_variables for input\n",
    "from tengwar.eval import do_per_frame_performance, do_per_episode_combined_performance, make_firstN_indeces # performance evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.config.optdb.max_use_ratio # A ratio that prevents infinite loop in EquilibriumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH   = '/home/mldata/KDD/medical1' # path to data folder\n",
    "SPLIT = 4   # i-th data split to use.\n",
    "FIRSTN = 3  # how many windows to use for FirstN experiments\n",
    "            # 3 = first 24 hours\n",
    "\n",
    "# similarity to use for Laplacian regularizer\n",
    "S_MAT = None      # none; 'No prior' in KDD15 paper\n",
    "#S_MAT = 'Sinf'   # infectious diseases\n",
    "#S_MAT = 'Sont'   # ontology tree; 'ICD-9 Tree' prior in KDD15 paper\n",
    "#S_MAT = 'Sprob'  # pairwise joint probability; 'Co-occurance' prior in KDD15 paper\n",
    "#S_MAT = 'Scos'   # pairwise cosine similarity\n",
    "\n",
    "# type of Laplacian regularizer\n",
    "S_TYPE = None     # no regularizer\n",
    "#S_TYPE = 'l2'    # traditional Laplacian regularizer\n",
    "#S_TYPE = 'l1'    # shared sparsity regularizer\n",
    "\n",
    "LAMBDA_S    = None # strength of Laplacian regularizer\n",
    "\n",
    "\n",
    "SHALLOW = False   # train shallow model with no hidden layers\n",
    "HL = []           # number of nodes in each hidden layer\n",
    "CL = []           # corruption level used to train a Denoising AE in each layer\n",
    "if not SHALLOW and (not HL and not CL): # set default parameters of network\n",
    "    HL = [500,100,100]\n",
    "    CL = [0.3,0.3,0.3]\n",
    "assert(len(HL) == len(CL))\n",
    "    \n",
    "LAMBDA_O_L2 = 0.0001    # plain L2 regularization of outputs\n",
    "LAMBDA_O_L1 = 0.0001    # plain L1 regularization of outputs\n",
    "LAMBDA_H_L2 = 0.00001    # L2 regularization of hidden unit weights\n",
    "\n",
    "USE_CLASS_WEIGHTS = False  # use re-weighting for class imbalance\n",
    "\n",
    "\n",
    "# file prefix to save the performance details and weights\n",
    "if not SHALLOW:\n",
    "    fn_prefix = 'weights-medical1-split{2:02d}-hl{0}-co{1}'.format('_'.join([ str(h) for h in HL ]),\n",
    "                                                                  '_'.join([ str(c) for c in CL ]),\n",
    "                                                                  SPLIT)\n",
    "else:\n",
    "    fn_prefix = 'weights-medical1-split{0:02d}-shallow'.format(SPLIT)\n",
    "\n",
    "# file suffix to encode configuration into file name\n",
    "fn_suffix = ''\n",
    "if not SHALLOW:\n",
    "    if S_MAT is None:\n",
    "        fn_suffix = fn_suffix + '-Snone'\n",
    "    else:\n",
    "        LAMBDA_S = LAMBDA_S if LAMBDA_S is not None else 0.0001\n",
    "        fn_suffix = fn_suffix + '-' + S_MAT + '_' + '{0}'.format(LAMBDA_S)\n",
    "    fn_suffix = fn_suffix + ('-Ol2{0}'.format(LAMBDA_O_L2) if LAMBDA_O_L2 is not None else '')\n",
    "    fn_suffix = fn_suffix + ('-Ol1{0}'.format(LAMBDA_O_L1) if LAMBDA_O_L1 is not None else '')\n",
    "    fn_suffix = fn_suffix + ('-Hl2{0}'.format(LAMBDA_H_L2) if LAMBDA_H_L2 is not None else '')\n",
    "\n",
    "#numpy_rng = np.random.RandomState(89677)\n",
    "numpy_rng = np.random.RandomState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variables for per-frame data\n",
    "SUB_FOLDER = 'frames-60min-frame12-stride6'\n",
    "LABEL_FILE = 'labels_etc.npz' # file that contains all the raw data except the featues\n",
    "\n",
    "# in the two following files, each variable is sampled uniformly.\n",
    "# missing data has been handled using some forward-backward pass with the previous values or empirical mean\n",
    "FEATURE_FILE = 'features-imputed.npy' # file that contains raw features\n",
    "FRAME_FILE = 'frames-imputed.npy' # file that contains raw frames (different level from FEATURE_FILE)\n",
    "\n",
    "ndata = np.load(os.path.join(PATH, SUB_FOLDER, LABEL_FILE))\n",
    "Y = ndata['Y'].astype(int) # labels (outcomes)\n",
    "split = ndata['split'] # a number of splits which are used for training, validation and testing.\n",
    "Ep = ndata['Ep'].ravel() # id of the episode that this frame belongs to\n",
    "X = np.load(os.path.join(PATH, SUB_FOLDER, FEATURE_FILE)) # raw features\n",
    "#X = np.load(os.path.join(PATH, SUB_FOLDER, FRAME_FILE)) # raw frames\n",
    "X = X.reshape(X.shape[0],-1).astype(theano.config.floatX) # flatten each feathres to from P*T to D*1\n",
    "\n",
    "# indices for training, validation and test set\n",
    "trix = split[:,SPLIT]==0\n",
    "vix = split[:,SPLIT]==1\n",
    "teix = split[:,SPLIT]==2\n",
    "\n",
    "# set class weights to be used in objective function\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    PY_EMP = YE[trix].mean(axis=0)\n",
    "else:\n",
    "    PY_EMP = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Per-episode data. VAR_E is simiar to VAR in per-frame data.\n",
    "\n",
    "ndata = np.load(os.path.join(PATH, 'medical1-60min.npz'))\n",
    "S_MATRIX = ndata[S_MAT] if S_MAT is not None else None\n",
    "\n",
    "YE = ndata['Y'].astype(int)\n",
    "splitE = ndata['split']\n",
    "EpE = ndata['Ep'].ravel() # id of this episode\n",
    "\n",
    "ydlist = ndata['ydlist']\n",
    "yclist = ndata['yclist']\n",
    "ylist = np.hstack([ydlist,yclist])\n",
    "\n",
    "trixE = splitE[:,SPLIT]==0\n",
    "vixE  = splitE[:,SPLIT]==1\n",
    "teixE = splitE[:,SPLIT]==2\n",
    "\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    PY_EMP_E = YE[trixE].mean(axis=0)\n",
    "else:\n",
    "    PY_EMP_E = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create shared_variables of X and Y\n",
    "print 'Creating shared variables to store data'\n",
    "XtrS,YtrS = make_theano_shared(X[trix],Y[trix])\n",
    "XvS,YvS   = make_theano_shared(X[vix],Y[vix])\n",
    "XteS,YteS = make_theano_shared(X[teix],Y[teix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make neural net object\n",
    "\n",
    "reload(tengwar.nnet)\n",
    "reload(tengwar.nnet.NewSdA)\n",
    "# describe all hyperparameters\n",
    "sda = tengwar.nnet.NewSdA.NewSdA(numpy_rng, n_ins=X.shape[1], n_outs=Y.shape[1],\n",
    "                                 hidden_layers_sizes=HL, corruption_levels=CL,\n",
    "                                 Py_emp=PY_EMP, S_matrix=S_MATRIX, S_type=S_TYPE,\n",
    "                                 lambda_S=LAMBDA_S, lambda_O_l2=LAMBDA_O_L2,\n",
    "                                 lambda_O_l1=LAMBDA_O_L1, lambda_H_l2=LAMBDA_H_L2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do unsupervised pretraining\n",
    "fn_prefix_unsup = fn_prefix + '-pretrain'\n",
    "# we will not do unsupervised pretraining if we can reload the pretrained parameters\n",
    "if not SHALLOW:\n",
    "    if os.path.isfile(fn_prefix_unsup + '.npz'):\n",
    "        print 'Loading pretrain weights from file ' + fn_prefix_unsup + '.npz'\n",
    "        sda.load_pretrained_params(fn_prefix_unsup + '.npz')\n",
    "    else:\n",
    "        print 'Running pretraining'\n",
    "        sda.do_unsupervised_pretraining(train_set_x=XtrS, epochs=100,\n",
    "                                        learn_rate=0.01, batch_size=200,\n",
    "                                        save_fnbase=fn_prefix_unsup)\n",
    "else:\n",
    "    print 'Shallow model so no pretraining'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do supervised finetuning\n",
    "fn_prefix_sup = fn_prefix + '-finetuned'\n",
    "sda.do_supervised_finetuning(train_set_x=XtrS, train_set_y=YtrS,\n",
    "                             valid_set_x=XvS, valid_set_y=YvS,\n",
    "                             test_set_x=XteS, test_set_y=YteS,\n",
    "                             epochs=1000, batch_size=200, learn_rate=0.1,\n",
    "                             use_auc=False, save_fnbase=fn_prefix_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "The cells below compute performance metrics and save them to their respective files. The file names are created using the prefixes and suffixes computed above. The file names encode the configuration of the nnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(tengwar.eval)\n",
    "fn_prefix_perf = fn_prefix.replace('weights', 'performance')\n",
    "\n",
    "print 'Compute per-frame performance:'\n",
    "fn_best = fn_prefix_sup + '-best.npz'\n",
    "nn = tengwar.nnet.FeedForwardNetwork.from_saved_weights(fn_best)\n",
    "Pf = tengwar.eval.do_per_frame_performance(nn, X, Y, trix, teix, ydlist, yclist)\n",
    "Pf.to_csv(fn_prefix_perf + '-frame.csv')\n",
    "Pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print 'Compute per-episode performance by combination:'\n",
    "Pc = tengwar.eval.do_per_episode_combined_performance(nn, Ep, EpE, X, YE, trixE, teixE, ydlist, yclist)\n",
    "Pc.to_csv(fn_prefix_perf + '-episode.csv')\n",
    "Pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print 'Compute per-frame first N performance:'\n",
    "IxN = tengwar.eval.make_firstN_indeces(Ep)\n",
    "XN = X[IxN]\n",
    "YN = Y[IxN]\n",
    "EpN = Ep[IxN]\n",
    "trixN = trix[IxN]\n",
    "teixN = teix[IxN]\n",
    "\n",
    "PfN = tengwar.eval.do_per_frame_performance(nn, XN, YN, trixN, teixN, ydlist, yclist=yclist)\n",
    "PfN.to_csv(fn_prefix_perf + '-frame-first{0}.csv'.format(FIRSTN))\n",
    "PfN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print 'Compute per-episode first N performance by combination:'\n",
    "PcN = tengwar.eval.do_per_episode_combined_performance(nn, EpN, EpE, XN, YE, trixE, teixE, ydlist, yclist)\n",
    "PcN.to_csv(fn_prefix_perf + '-episode-first{0}.csv'.format(FIRSTN))\n",
    "PcN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Classifier using the features learnt by the nnet.\n",
    "'''\n",
    "\n",
    "print 'fitting per-episode classifier, all feats...'\n",
    "HN = nn.transform_features(XN)\n",
    "HE = np.vstack([ HN[EpN==e].ravel() for e in EpE ])\n",
    "\n",
    "\n",
    "print 'One vs. Rest sklearn classifier'\n",
    "fn_prefix_cl = fn_prefix_perf + '-episode-onevsrest'\n",
    "fn_prefix_cl = fn_prefix_cl.replace('weights', 'performance')\n",
    "# cl = OneVsRestClassifier(LinearSVC(penalty='l2', C=100.0, class_weight=None, dual=False), n_jobs=-1)\n",
    "cl = OneVsRestClassifier(LogisticRegression(penalty='l2', C=1, class_weight=None), n_jobs=-1)\n",
    "cl.fit(HE[trixE], YE[trixE])\n",
    "print 'done!'\n",
    "\n",
    "Pe = tengwar.eval.do_per_frame_performance(cl, HE, YE, trixE, teixE, ydlist, yclist)\n",
    "Pe.to_csv(fn_prefix_cl + '.csv')\n",
    "Pe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
